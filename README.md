# Frame Vision Translation

Uses the Brilliant Labs Frame camera to take a picture that includes some text, uses Google ML Kit text recognition then translation to translate the text and display it on Frame. All processing is done with local on-device models on the phone and takes about 3 seconds from triple-tap to display.

This demo currently only performs Japanese to English translation, although other script is possible. (Some screenshots show images from when Chinese/English was specified.)

### Frameshots
![Frameshot1](docs/frameshot1.png)
![Frameshot2](docs/frameshot2.jpg)
![Frameshot3](docs/frameshot3.jpg)
![Frameshot4](docs/frameshot4.jpg)

### Framecast

https://github.com/user-attachments/assets/19538773-a0c0-47b2-8d23-7e9fd5c66f6a

### Screenshots
![Screenshot1](docs/screenshot1.png)
![Screenshot2](docs/screenshot2.png)
![Screenshot3](docs/screenshot3.png)
![Screenshot4](docs/screenshot4.png)

### Architecture
![Architecture](docs/Frame%20App%20Architecture%20-%20Vision%20-%20Translation.svg)
